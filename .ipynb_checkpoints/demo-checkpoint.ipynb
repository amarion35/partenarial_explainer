{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audit Data is a dataset with audit score and risks factors. The objective is to understand if/why a company is fraudulent.\n",
    "https://www.kaggle.com/sid321axn/audit-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((776, 24), (776, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit = pd.read_csv('./datasets/audit_data.csv', sep=';')\n",
    "Xt = audit.drop(labels=['LOCATION_ID', 'Audit_Risk', 'Risk'], axis=1)\n",
    "X = (Xt-Xt.min())/(Xt.max()-Xt.min())\n",
    "X = np.array(X)\n",
    "X[np.isnan(X)] = -1\n",
    "y = np.array(audit['Risk'])\n",
    "y = y.astype(np.int).reshape(-1,1)\n",
    "n_class = 2\n",
    "n_features = len(Xt.columns)\n",
    "Xt.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human-Resource-Analytics-Kaggle-Dataset is a dataset with professionnal informations of employees. The objective is to unerstand why someone leave a company. https://github.com/ryankarlos/Human-Resource-Analytics-Kaggle-Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hr = pd.read_csv('./datasets/HR_comma_sep.csv')\n",
    "Xt = hr.drop(labels=['sales', 'salary', 'left'], axis=1)\n",
    "X = (Xt-Xt.min())/(Xt.max()-Xt.min())\n",
    "X = np.array(X)\n",
    "X[np.isnan(X)] = -1\n",
    "y = np.array(hr['left'])\n",
    "y = y.astype(np.int).reshape(-1,1)\n",
    "n_class = 2\n",
    "n_features = len(Xt.columns)\n",
    "Xt.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bank_Loan_Classification is a dataset with banking informations of clients. Our objective is understand why someone doesn't have a loan.\n",
    "https://www.kaggle.com/sriharipramod/bank-loan-classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bank = pd.read_csv('./datasets/UniversalBank.csv', sep=';')\n",
    "Xt = bank.drop(labels=['ID', 'ZIP Code', 'Personal Loan'], axis=1)\n",
    "X = (Xt-Xt.min())/(Xt.max()-Xt.min())\n",
    "X = np.array(X)\n",
    "X[np.isnan(X)] = -1\n",
    "y = np.array(bank['Personal Loan'])\n",
    "y = y.astype(np.int).reshape(-1,1)\n",
    "y = (y==0).astype(np.int)\n",
    "n_class = 2\n",
    "n_features = len(Xt.columns)\n",
    "Xt.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388, 24), (388, 24), (388, 1), (388, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.012887\ttrain-merror:0.005155\n",
      "[1]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[2]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[3]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[4]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[5]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[6]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[7]\teval-merror:0.012887\ttrain-merror:0.002577\n",
      "[8]\teval-merror:0.007732\ttrain-merror:0\n",
      "[9]\teval-merror:0.007732\ttrain-merror:0\n",
      "[10]\teval-merror:0.007732\ttrain-merror:0\n",
      "[11]\teval-merror:0.007732\ttrain-merror:0\n",
      "[12]\teval-merror:0.007732\ttrain-merror:0\n",
      "[13]\teval-merror:0.007732\ttrain-merror:0\n",
      "[14]\teval-merror:0.007732\ttrain-merror:0\n",
      "[15]\teval-merror:0.007732\ttrain-merror:0\n",
      "[16]\teval-merror:0.007732\ttrain-merror:0\n",
      "[17]\teval-merror:0.007732\ttrain-merror:0\n",
      "[18]\teval-merror:0.007732\ttrain-merror:0\n",
      "[19]\teval-merror:0.007732\ttrain-merror:0\n",
      "[20]\teval-merror:0.007732\ttrain-merror:0\n",
      "[21]\teval-merror:0.007732\ttrain-merror:0\n",
      "[22]\teval-merror:0.007732\ttrain-merror:0\n",
      "[23]\teval-merror:0.007732\ttrain-merror:0\n",
      "[24]\teval-merror:0.007732\ttrain-merror:0\n",
      "[25]\teval-merror:0.007732\ttrain-merror:0\n",
      "[26]\teval-merror:0.007732\ttrain-merror:0\n",
      "[27]\teval-merror:0.007732\ttrain-merror:0\n",
      "[28]\teval-merror:0.007732\ttrain-merror:0\n",
      "[29]\teval-merror:0.007732\ttrain-merror:0\n",
      "[30]\teval-merror:0.007732\ttrain-merror:0\n",
      "[31]\teval-merror:0.007732\ttrain-merror:0\n",
      "[32]\teval-merror:0.005155\ttrain-merror:0\n",
      "[33]\teval-merror:0.005155\ttrain-merror:0\n",
      "[34]\teval-merror:0.005155\ttrain-merror:0\n",
      "[35]\teval-merror:0.005155\ttrain-merror:0\n",
      "[36]\teval-merror:0.005155\ttrain-merror:0\n",
      "[37]\teval-merror:0.005155\ttrain-merror:0\n",
      "[38]\teval-merror:0.005155\ttrain-merror:0\n",
      "[39]\teval-merror:0.005155\ttrain-merror:0\n",
      "[40]\teval-merror:0.005155\ttrain-merror:0\n",
      "[41]\teval-merror:0.005155\ttrain-merror:0\n",
      "[42]\teval-merror:0.005155\ttrain-merror:0\n",
      "[43]\teval-merror:0.005155\ttrain-merror:0\n",
      "[44]\teval-merror:0.005155\ttrain-merror:0\n",
      "[45]\teval-merror:0.005155\ttrain-merror:0\n",
      "[46]\teval-merror:0.005155\ttrain-merror:0\n",
      "[47]\teval-merror:0.005155\ttrain-merror:0\n",
      "[48]\teval-merror:0.005155\ttrain-merror:0\n",
      "[49]\teval-merror:0.005155\ttrain-merror:0\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train.copy(), y_train.copy(), missing=np.nan)\n",
    "dtest = xgb.DMatrix(X_test.copy(), y_test.copy(), missing=np.nan)\n",
    "\n",
    "\n",
    "lmda = 2.0\n",
    "params = {\n",
    "    \"objective\":\"multi:softprob\", \n",
    "    'num_class': len(np.unique(y)), \n",
    "    'silent': 1, \n",
    "    'eval_metric': 'merror', \n",
    "    'base_score':0, \n",
    "    \"lambda\":lmda, \n",
    "    'max_depth': 4\n",
    "}\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "best_iteration = 50\n",
    "\n",
    "bst = xgb.train(params, dtrain, best_iteration, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948453608247423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bst.predict(dtest)\n",
    "accuracy_score(pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = OneHotEncoder(categories='auto').fit_transform(y_train).toarray()\n",
    "y_test = OneHotEncoder(categories='auto').fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DFE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimators.dfe import DFE\n",
    "import torch\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = DFE(bst, n_class=n_class, n_features=n_features, w_init=10e0, device=device)\n",
    "dfe.fit(X_train.copy(), y_train.copy(), X_val=X_test.copy(), Y_val=y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = dfe.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = softmax(bst.predict(dtest, output_margin=True))\n",
    "p1 = softmax(dfe.predict(X_test, softmax=False), axis=1)\n",
    "p2 = softmax(dfe.predict_model(bst, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = softmax(bst.predict(dtest, output_margin=True))\n",
    "\n",
    "p0p1 = []\n",
    "\n",
    "x = 10**((np.arange(10)/1)-3)\n",
    "for i in x:\n",
    "    dfe_i = DFE(bst, n_class=n_class, n_features=n_features, w_init=i, device=device)\n",
    "    dfe_i.fit(X_train.copy(), y_train.copy(), X_val=X_test.copy(), Y_val=y_test.copy())\n",
    "    p1 = softmax(dfe_i.predict(X_test, softmax=False))\n",
    "    p0p1.append(accuracy_score(p0.argmax(1), p1.argmax(1)))\n",
    "    del(dfe_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, p0p1)\n",
    "plt.xscale('log')\n",
    "plt.grid(which='both')\n",
    "plt.title('Estimator accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select faulty example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = torch.argmax(bmodel(torch.tensor(X_test), training=False), dim=1).data.numpy()\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "FC_index = np.logical_and(pred_test==Y_test,Y_test==1)\n",
    "FC_X = X_test[FC_index]\n",
    "FC_Y = Y_test[FC_index]\n",
    "sample_idx = np.random.choice(range(len(FC_X)))\n",
    "x = FC_X[sample_idx]\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search partenarial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DDN.ddn import DDN\n",
    "import torch.nn as nn\n",
    "\n",
    "Loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "ddn = DDN(bmodel, Loss, alpha=1, gamma=0.05)\n",
    "xa = ddn.fit(x, y, n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_idx = np.array(list(range(xa[-1].size(1))))\n",
    "xadv = xa[-1][0].data.numpy()\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(13,7))\n",
    "\n",
    "plt.bar(col_idx-width/2, x, width, tick_label=Xt.columns, label='original (faulty)', color='tab:red')\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "\n",
    "plt.bar(col_idx+width/2, xadv, width, tick_label=Xt.columns, label='partenarial (non-faulty)', color='tab:green')\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Original-Partenarial comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_terpret70",
   "language": "python",
   "name": "conda_terpret70"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
